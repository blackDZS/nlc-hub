# 当前实验使用的设备
device: "cuda:0"

trainer_type: bert
model_name_or_path: bert-base-chinese
tokenizer_name_or_path: bert-base-chinese
data_path: data/data.csv
output_dir: ./logs/bert_model/bert-v1
batch_size: 64
epochs: 3
learning_rate: 2e-5
max_length: 512
test_ratio: 0.2
swanlab:
  project: Tele-fraud-Classify
  experiment_name: BERT-v1